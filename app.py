"""
ì‡¼íŠ¹í—ˆ (Short-Cut) v3.0 - Streamlit Web Application with Streaming
====================================================================
AI ê¸°ë°˜ íŠ¹í—ˆ ì„ í–‰ ê¸°ìˆ  ì¡°ì‚¬ ì‹œìŠ¤í…œ

Features:
- Zero-latency startup with @st.cache_resource
- Pre-loaded FAISS + BM25 hybrid index
- LLM Streaming response for real-time analysis
- Async pipeline with ThreadPoolExecutor

Team: ë€¨ğŸ’•
License: MIT
"""

import streamlit as st
import asyncio
import nest_asyncio
import sys
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

# Apply nest_asyncio for Streamlit compatibility
nest_asyncio.apply()

# Add src to path for imports
SRC_DIR = Path(__file__).parent / "src"
sys.path.insert(0, str(SRC_DIR))

# =============================================================================
# Page Configuration
# =============================================================================

st.set_page_config(
    page_title="ì‡¼íŠ¹í—ˆ (Short-Cut) v3.0",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =============================================================================
# Custom CSS for Modern Design
# =============================================================================

st.markdown("""
<style>
    /* Main container */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Metric cards with dynamic colors */
    .metric-low {
        background: linear-gradient(135deg, #1a472a 0%, #2d5016 100%);
        border-radius: 12px;
        padding: 1.5rem;
        text-align: center;
        border: 1px solid #2d5016;
    }
    .metric-medium {
        background: linear-gradient(135deg, #5c4a1f 0%, #6b5b1f 100%);
        border-radius: 12px;
        padding: 1.5rem;
        text-align: center;
        border: 1px solid #6b5b1f;
    }
    .metric-high {
        background: linear-gradient(135deg, #5c1a1a 0%, #6b1f1f 100%);
        border-radius: 12px;
        padding: 1.5rem;
        text-align: center;
        border: 1px solid #6b1f1f;
    }
    
    /* Risk badge */
    .risk-badge {
        font-size: 0.9rem;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-weight: 600;
    }
    .risk-high { background: #dc3545; color: white; }
    .risk-medium { background: #ffc107; color: black; }
    .risk-low { background: #28a745; color: white; }
    
    /* Analysis section */
    .analysis-section {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid #4a90d9;
    }
    
    /* Streaming text animation */
    .streaming-text {
        border-left: 3px solid #4a90d9;
        padding-left: 1rem;
        animation: pulse 1s infinite;
    }
    
    @keyframes pulse {
        0%, 100% { border-left-color: #4a90d9; }
        50% { border-left-color: #1a5490; }
    }
    
    /* Header styling */
    .main-header {
        text-align: center;
        padding: 1rem 0 2rem 0;
    }
    
    /* Sidebar */
    .sidebar .sidebar-content {
        padding: 1rem;
    }
</style>
""", unsafe_allow_html=True)


# =============================================================================
# Cached Resource Loading (Zero-Latency Startup)
# =============================================================================

@st.cache_resource
def load_db_client():
    """Load Pinecone + BM25 hybrid client."""
    from vector_db import PineconeClient
    
    # PineconeClient automatically connects to serverless index
    # and loads local BM25 index if available
    client = PineconeClient()
    client.load_local()  # Load local BM25 index and metadata cache
    
    try:
        stats = client.get_stats()
    except:
        stats = {"total_vectors": 0, "initialized": False}
        
    return client, stats


@st.cache_resource
def get_openai_api_key():
    """Get OpenAI API key from environment."""
    import os
    from dotenv import load_dotenv
    load_dotenv()
    return os.environ.get("OPENAI_API_KEY", "")


@st.cache_resource
def get_executor():
    """Get thread pool executor for async operations."""
    return ThreadPoolExecutor(max_workers=4)


# Load resources at startup
DB_CLIENT, DB_STATS = load_db_client()
OPENAI_API_KEY = get_openai_api_key()
EXECUTOR = get_executor()


# =============================================================================
# Session State Initialization
# =============================================================================

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []
if "current_result" not in st.session_state:
    st.session_state.current_result = None
if "streaming_text" not in st.session_state:
    st.session_state.streaming_text = ""


# =============================================================================
# Helper Functions
# =============================================================================

def get_risk_color(risk_level: str) -> tuple:
    """Get color scheme based on risk level."""
    colors = {
        "high": ("#dc3545", "ğŸ”´", "metric-high"),
        "medium": ("#ffc107", "ğŸŸ¡", "metric-medium"),
        "low": ("#28a745", "ğŸŸ¢", "metric-low"),
    }
    return colors.get(risk_level.lower(), ("#6c757d", "âšª", "metric-low"))


def get_score_color(score: int) -> str:
    """Get color based on similarity score."""
    if score >= 70:
        return "#dc3545"
    elif score >= 40:
        return "#ffc107"
    else:
        return "#28a745"


def format_analysis_markdown(result: dict) -> str:
    """Format analysis result as downloadable markdown."""
    analysis = result.get("analysis", {})
    
    md = f"""# âš¡ ì‡¼íŠ¹í—ˆ (Short-Cut) Analysis Report
> Generated: {result.get('timestamp', datetime.now().isoformat())}
> Search Type: {result.get('search_type', 'hybrid').upper()}

## ğŸ’¡ User Idea
{result.get('user_idea', 'N/A')}

---

## ğŸ“Š Analysis Summary

### [1. ìœ ì‚¬ë„ í‰ê°€] Similarity Assessment
- **Score**: {analysis.get('similarity', {}).get('score', 0)}/100
- **Summary**: {analysis.get('similarity', {}).get('summary', 'N/A')}
- **Common Elements**: {', '.join(analysis.get('similarity', {}).get('common_elements', []))}
- **Evidence Patents**: {', '.join(analysis.get('similarity', {}).get('evidence', []))}

### [2. ì¹¨í•´ ë¦¬ìŠ¤í¬] Infringement Risk
- **Risk Level**: {analysis.get('infringement', {}).get('risk_level', 'unknown').upper()}
- **Summary**: {analysis.get('infringement', {}).get('summary', 'N/A')}
- **Risk Factors**:
{chr(10).join(['  - ' + f for f in analysis.get('infringement', {}).get('risk_factors', [])])}
- **Evidence Patents**: {', '.join(analysis.get('infringement', {}).get('evidence', []))}

### [3. íšŒí”¼ ì „ëµ] Avoidance Strategy
- **Summary**: {analysis.get('avoidance', {}).get('summary', 'N/A')}
- **Strategies**:
{chr(10).join(['  - ' + s for s in analysis.get('avoidance', {}).get('strategies', [])])}
- **Alternatives**: {', '.join(analysis.get('avoidance', {}).get('alternatives', []))}

---

## ğŸ“Œ Conclusion
{analysis.get('conclusion', 'N/A')}

---

## ğŸ“š Referenced Patents
"""
    for patent in result.get("search_results", []):
        rrf = patent.get('rrf_score', 0)
        md += f"\n- **{patent.get('patent_id')}**: Score: {patent.get('grading_score', 0):.2f} | RRF: {rrf:.4f}"
    
    md += "\n\n---\n*Generated by ì‡¼íŠ¹í—ˆ (Short-Cut) v3.0 | Team ë€¨ğŸ’•*"
    
    return md


def run_async_in_thread(coro):
    """Run async coroutine in a new event loop in thread."""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(coro)
    finally:
        loop.close()


async def run_search_phase(agent, user_idea: str, use_hybrid: bool = True):
    """Run search and grading phase."""
    from patent_agent import PatentSearchResult
    
    # HyDE search
    hypothetical_claim, _ = await agent.hyde_search(user_idea, use_hybrid=use_hybrid)
    
    # Search with grading
    results = await agent.search_with_grading(user_idea, use_hybrid=use_hybrid)
    
    return hypothetical_claim, results


async def run_analysis_streaming(agent, user_idea: str, results, output_container):
    """Run streaming analysis and display in real-time."""
    full_text = ""
    placeholder = output_container.empty()
    
    async for token in agent.critical_analysis_stream(user_idea, results):
        full_text += token
        placeholder.markdown(full_text + "â–Œ")  # Cursor effect
    
    placeholder.markdown(full_text)  # Final output without cursor
    return full_text


async def run_full_analysis(user_idea: str, status_container, streaming_container, use_hybrid: bool = True):
    """Run the complete patent analysis with streaming."""
    from patent_agent import PatentAgent, CriticalAnalysisResponse
    
    # Create agent with cached DB client
    agent = PatentAgent(db_client=DB_CLIENT)
    
    results = []
    analysis = None
    
    with status_container.status("ğŸ” íŠ¹í—ˆ ë¶„ì„ ì¤‘...", expanded=True) as status:
        # Step 1: HyDE
        status.write("ğŸ“ **Step 1/4**: HyDE - ê°€ìƒ ì²­êµ¬í•­ ìƒì„± ì¤‘...")
        hypothetical_claim = await agent.generate_hypothetical_claim(user_idea)
        status.write(f"âœ… ê°€ìƒ ì²­êµ¬í•­ ìƒì„± ì™„ë£Œ")
        status.write(f"```\n{hypothetical_claim[:200]}...\n```")
        
        # Step 2: Hybrid Search
        search_type = "Hybrid (Dense + BM25)" if use_hybrid else "Dense Only"
        status.write(f"ğŸ” **Step 2/4**: {search_type} ê²€ìƒ‰ ì¤‘...")
        
        query_embedding = await agent.embed_text(hypothetical_claim)
        keywords = await agent.extract_keywords(user_idea + " " + hypothetical_claim)
        query_text = " ".join(keywords)
        
        if use_hybrid:
            search_results = await agent.db_client.async_hybrid_search(
                query_embedding, query_text, top_k=5
            )
        else:
            search_results = await agent.db_client.async_search(query_embedding, top_k=5)
        
        from patent_agent import PatentSearchResult
        results = []
        for r in search_results:
            results.append(PatentSearchResult(
                publication_number=r.patent_id,
                title=r.metadata.get("title", ""),
                abstract=r.metadata.get("abstract", r.content[:500]),
                claims=r.metadata.get("claims", ""),
                ipc_codes=[r.metadata.get("ipc_code", "")] if r.metadata.get("ipc_code") else [],
                similarity_score=r.score,
                dense_score=getattr(r, 'dense_score', 0.0),
                sparse_score=getattr(r, 'sparse_score', 0.0),
                rrf_score=getattr(r, 'rrf_score', 0.0),
            ))
        
        status.write(f"âœ… {len(results)}ê°œ ìœ ì‚¬ íŠ¹í—ˆ ë°œê²¬")
        
        # Step 3: Grading
        status.write("ğŸ“Š **Step 3/4**: ê´€ë ¨ì„± í‰ê°€ ì¤‘...")
        grading = await agent.grade_results(user_idea, results)
        status.write(f"âœ… í‰ê·  ê´€ë ¨ì„± ì ìˆ˜: {grading.average_score:.2f}")
        
        status.update(label="âœ… ê²€ìƒ‰ ì™„ë£Œ! ë¶„ì„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...", state="complete", expanded=False)
    
    # Step 4: Streaming Analysis
    streaming_container.markdown("### ğŸ§  ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼")
    streaming_container.caption("AIê°€ ë¶„ì„ ë‚´ìš©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
    
    streamed_text = await run_analysis_streaming(agent, user_idea, results, streaming_container)
    
    # Also get structured analysis for result storage
    analysis = await agent.critical_analysis(user_idea, results)
    
    # Build result
    result = {
        "user_idea": user_idea,
        "search_results": [
            {
                "patent_id": r.publication_number,
                "title": r.title,
                "abstract": r.abstract,
                "claims": r.claims,
                "grading_score": r.grading_score,
                "grading_reason": r.grading_reason,
                "rrf_score": r.rrf_score,
            }
            for r in results
        ],
        "analysis": {
            "similarity": {
                "score": analysis.similarity.score,
                "common_elements": analysis.similarity.common_elements,
                "summary": analysis.similarity.summary,
                "evidence": analysis.similarity.evidence_patents,
            },
            "infringement": {
                "risk_level": analysis.infringement.risk_level,
                "risk_factors": analysis.infringement.risk_factors,
                "summary": analysis.infringement.summary,
                "evidence": analysis.infringement.evidence_patents,
            },
            "avoidance": {
                "strategies": analysis.avoidance.strategies,
                "alternatives": analysis.avoidance.alternative_technologies,
                "summary": analysis.avoidance.summary,
                "evidence": analysis.avoidance.evidence_patents,
            },
            "component_comparison": {
                "idea_components": analysis.component_comparison.idea_components,
                "matched_components": analysis.component_comparison.matched_components,
                "unmatched_components": analysis.component_comparison.unmatched_components,
                "risk_components": analysis.component_comparison.risk_components,
            },
            "conclusion": analysis.conclusion,
        },
        "streamed_analysis": streamed_text,
        "timestamp": datetime.now().isoformat(),
        "search_type": "hybrid" if use_hybrid else "dense",
    }
    
    return result


# =============================================================================
# Sidebar
# =============================================================================

with st.sidebar:
    st.markdown("# âš¡ ì‡¼íŠ¹í—ˆ")
    st.markdown("### Short-Cut v3.0")
    st.divider()
    
    # System Status
    st.markdown("### âš¡ System Status")
    
    # API Status
    if OPENAI_API_KEY:
        st.success("âœ… OpenAI API ì—°ê²°ë¨")
    else:
        st.error("âŒ OpenAI API í‚¤ ì—†ìŒ")
        st.info("`.env` íŒŒì¼ì— `OPENAI_API_KEY`ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    
    # DB Index Status
    if DB_CLIENT:
        st.success(f"âœ… Hybrid ì¸ë±ìŠ¤ ë¡œë“œë¨")
        st.caption(f"   ğŸŒ² Pinecone: Connected")
        if DB_STATS.get('bm25_initialized'):
            st.caption(f"   ğŸ“ BM25 (Local): {DB_STATS.get('bm25_docs', 0):,}ê°œ ë¬¸ì„œ")
    else:
        st.warning("âš ï¸ DB ì—°ê²° ì‹¤íŒ¨")
        st.info("íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”:\n`python src/pipeline.py --stage 5`")
    
    st.divider()
    
    # Search Options
    st.markdown("### ğŸ”§ ê²€ìƒ‰ ì˜µì…˜")
    use_hybrid = st.toggle("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Dense + BM25)", value=True)
    if use_hybrid:
        st.caption("RRF ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ Denseì™€ Sparse ê²°ê³¼ë¥¼ ìœµí•©í•©ë‹ˆë‹¤.")
    else:
        st.caption("Dense (ë²¡í„°) ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    st.divider()
    
    # Analysis History
    st.markdown("### ğŸ“œ ë¶„ì„ íˆìŠ¤í† ë¦¬")
    if st.session_state.analysis_history:
        for i, hist in enumerate(reversed(st.session_state.analysis_history[-5:])):
            with st.expander(f"#{len(st.session_state.analysis_history)-i}: {hist['user_idea'][:20]}..."):
                risk = hist.get('analysis', {}).get('infringement', {}).get('risk_level', 'unknown')
                score = hist.get('analysis', {}).get('similarity', {}).get('score', 0)
                search_type = hist.get('search_type', 'unknown')
                st.write(f"ğŸ¯ ìœ ì‚¬ë„: {score}/100")
                st.write(f"âš ï¸ ë¦¬ìŠ¤í¬: {risk.upper()}")
                st.write(f"ğŸ” ê²€ìƒ‰: {search_type}")
                st.write(f"ğŸ• {hist.get('timestamp', 'N/A')[:10]}")
    else:
        st.caption("ì•„ì§ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    st.divider()
    
    # API Usage Guide
    st.markdown("### ğŸ’° API ë¹„ìš© ê°€ì´ë“œ")
    st.caption("""
    **ë¶„ì„ 1íšŒ ì˜ˆìƒ ë¹„ìš©**: ~$0.01-0.03
    
    - HyDE: gpt-4o-mini
    - Embed: text-embedding-3-small
    - Grading: gpt-4o-mini
    - Analysis: gpt-4o (Streaming)
    """)
    
    st.divider()
    st.markdown("##### Team ë€¨ğŸ’•")


# =============================================================================
# Main Content
# =============================================================================

# Header
st.markdown("""
<div class="main-header">
    <h1>âš¡ ì‡¼íŠ¹í—ˆ (Short-Cut) v3.0</h1>
    <p style="font-size: 1.2rem; color: #888;">AI ê¸°ë°˜ íŠ¹í—ˆ ì„ í–‰ ê¸°ìˆ  ì¡°ì‚¬ ì‹œìŠ¤í…œ</p>
    <p style="font-size: 0.9rem; color: #666;">Self-RAG | Hybrid Search | LLM Streaming</p>
</div>
""", unsafe_allow_html=True)

# Input Section
st.markdown("### ğŸ’¡ ì•„ì´ë””ì–´ ì…ë ¥")
st.caption("íŠ¹í—ˆë¡œ ì¶œì›í•˜ë ¤ëŠ” ì•„ì´ë””ì–´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”. ìœ ì‚¬ íŠ¹í—ˆë¥¼ ì°¾ì•„ ì¹¨í•´ ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

user_idea = st.text_area(
    label="ì•„ì´ë””ì–´ ì„¤ëª…",
    placeholder="ì˜ˆ: ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¬¸ì„œ ìš”ì•½ ì‹œìŠ¤í…œìœ¼ë¡œ, ê¸´ ë¬¸ì„œë¥¼ ì…ë ¥ë°›ì•„ í•µì‹¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ìš”ì•½ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤...",
    height=120,
    label_visibility="collapsed",
)

# Check if analysis is possible
can_analyze = (
    user_idea and 
    OPENAI_API_KEY and 
    DB_CLIENT
)

col1, col2, col3 = st.columns([1, 1, 1])
with col2:
    analyze_button = st.button(
        "ğŸ” íŠ¹í—ˆ ë¶„ì„ ì‹œì‘",
        type="primary",
        use_container_width=True,
        disabled=not can_analyze,
    )

if not can_analyze and user_idea:
    if not OPENAI_API_KEY:
        st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    elif not DB_CLIENT:
        st.warning("âš ï¸ DB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨.")

# Analysis Execution
if analyze_button and can_analyze:
    status_container = st.container()
    streaming_container = st.container()
    
    try:
        # Run async analysis using nest_asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(
            run_full_analysis(user_idea, status_container, streaming_container, use_hybrid=use_hybrid)
        )
        
        loop.close()
        
        # Store result
        st.session_state.current_result = result
        st.session_state.analysis_history.append(result)
        
    except Exception as e:
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ğŸ’¡ OpenAI API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


# =============================================================================
# Results Display
# =============================================================================

if st.session_state.current_result:
    result = st.session_state.current_result
    analysis = result.get("analysis", {})
    
    st.divider()
    st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    # Search Type Badge
    search_type = result.get("search_type", "hybrid")
    if search_type == "hybrid":
        st.success("ğŸ”€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Dense + BM25 + RRF)")
    else:
        st.info("ğŸ¯ Dense ê²€ìƒ‰")
    
    # Metric Cards
    col1, col2, col3 = st.columns(3)
    
    with col1:
        score = analysis.get("similarity", {}).get("score", 0)
        score_color = get_score_color(score)
        st.metric(
            label="ğŸ¯ ìœ ì‚¬ë„ ì ìˆ˜",
            value=f"{score}/100",
            delta="ìœ„í—˜" if score >= 70 else ("ì£¼ì˜" if score >= 40 else "ì–‘í˜¸"),
            delta_color="inverse" if score >= 40 else "normal",
        )
    
    with col2:
        risk_level = analysis.get("infringement", {}).get("risk_level", "unknown")
        color, emoji, css_class = get_risk_color(risk_level)
        st.metric(
            label="âš ï¸ ì¹¨í•´ ë¦¬ìŠ¤í¬",
            value=f"{emoji} {risk_level.upper()}",
        )
    
    with col3:
        patent_count = len(result.get("search_results", []))
        st.metric(
            label="ğŸ“š ì°¸ì¡° íŠ¹í—ˆ",
            value=f"{patent_count}ê±´",
        )
    
    st.divider()
    
    # Analysis Report Tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ ì¢…í•© ë¦¬í¬íŠ¸", "ğŸ¯ ìœ ì‚¬ë„ ë¶„ì„", "âš ï¸ ì¹¨í•´ ë¦¬ìŠ¤í¬", "ğŸ›¡ï¸ íšŒí”¼ ì „ëµ", "ğŸ”¬ êµ¬ì„±ìš”ì†Œ ëŒ€ë¹„"])
    
    with tab1:
        st.markdown("### ğŸ“Œ ê²°ë¡ ")
        st.info(analysis.get("conclusion", "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."))
        
        # Download button
        md_content = format_analysis_markdown(result)
        st.download_button(
            label="ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (Markdown)",
            data=md_content,
            file_name=f"shortcut_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown",
        )
    
    with tab2:
        similarity = analysis.get("similarity", {})
        st.markdown(f"### ìœ ì‚¬ë„ ì ìˆ˜: {similarity.get('score', 0)}/100")
        st.markdown(f"**ë¶„ì„ ìš”ì•½**: {similarity.get('summary', 'N/A')}")
        
        st.markdown("**ê³µí†µ ê¸°ìˆ  ìš”ì†Œ:**")
        for elem in similarity.get("common_elements", []):
            st.markdown(f"- {elem}")
        
        st.markdown("**ê·¼ê±° íŠ¹í—ˆ:**")
        for patent in similarity.get("evidence", []):
            st.code(patent)
    
    with tab3:
        infringement = analysis.get("infringement", {})
        risk = infringement.get("risk_level", "unknown")
        
        if risk == "high":
            st.error(f"ğŸ”´ **HIGH RISK** - ì¹¨í•´ ê°€ëŠ¥ì„± ë†’ìŒ")
        elif risk == "medium":
            st.warning(f"ğŸŸ¡ **MEDIUM RISK** - ì£¼ì˜ í•„ìš”")
        else:
            st.success(f"ğŸŸ¢ **LOW RISK** - ì¹¨í•´ ê°€ëŠ¥ì„± ë‚®ìŒ")
        
        st.markdown(f"**ë¶„ì„ ìš”ì•½**: {infringement.get('summary', 'N/A')}")
        
        st.markdown("**ìœ„í—˜ ìš”ì†Œ:**")
        for factor in infringement.get("risk_factors", []):
            st.markdown(f"- âš ï¸ {factor}")
        
        st.markdown("**ê·¼ê±° íŠ¹í—ˆ:**")
        for patent in infringement.get("evidence", []):
            st.code(patent)
    
    with tab4:
        avoidance = analysis.get("avoidance", {})
        st.markdown(f"**ê¶Œì¥ ì „ëµ**: {avoidance.get('summary', 'N/A')}")
        
        st.markdown("**íšŒí”¼ ì„¤ê³„ ë°©ì•ˆ:**")
        for strategy in avoidance.get("strategies", []):
            st.markdown(f"- âœ… {strategy}")
        
        st.markdown("**ëŒ€ì•ˆ ê¸°ìˆ :**")
        for alt in avoidance.get("alternatives", []):
            st.markdown(f"- ğŸ’¡ {alt}")
    
    with tab5:
        comp = analysis.get("component_comparison", {})
        st.markdown("### ğŸ”¬ êµ¬ì„±ìš”ì†Œ ëŒ€ë¹„í‘œ")
        st.caption("ì‚¬ìš©ì ì•„ì´ë””ì–´ì˜ êµ¬ì„±ìš”ì†Œì™€ ì„ í–‰ íŠ¹í—ˆ ë¹„êµ ë¶„ì„")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ“‹ ì•„ì´ë””ì–´ êµ¬ì„±ìš”ì†Œ")
            for c in comp.get("idea_components", []):
                st.markdown(f"- {c}")
        
        with col2:
            st.markdown("#### âœ… ì¼ì¹˜ (ì„ í–‰ íŠ¹í—ˆì— ì¡´ì¬)")
            for c in comp.get("matched_components", []):
                st.markdown(f"- ğŸ”´ {c}")
        
        st.divider()
        
        col3, col4 = st.columns(2)
        
        with col3:
            st.markdown("#### ğŸ†• ì‹ ê·œ (ì„ í–‰ íŠ¹í—ˆì— ì—†ìŒ)")
            for c in comp.get("unmatched_components", []):
                st.markdown(f"- ğŸŸ¢ {c}")
            if not comp.get("unmatched_components"):
                st.caption("ì‹ ê·œ êµ¬ì„±ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with col4:
            st.markdown("#### âš ï¸ ìœ„í—˜ êµ¬ì„±ìš”ì†Œ")
            for c in comp.get("risk_components", []):
                st.markdown(f"- ğŸŸ¡ {c}")
            if not comp.get("risk_components"):
                st.caption("íŠ¹ë³„íˆ ìœ„í—˜í•œ êµ¬ì„±ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # Referenced Patents
    st.divider()
    st.markdown("### ğŸ“š ì°¸ì¡°ëœ ì„ í–‰ íŠ¹í—ˆ")
    
    for patent in result.get("search_results", []):
        rrf = patent.get('rrf_score', 0)
        with st.expander(f"ğŸ“„ {patent.get('patent_id')} - Grade: {patent.get('grading_score', 0):.2f} | RRF: {rrf:.4f}"):
            st.markdown(f"**ì œëª©**: {patent.get('title', 'N/A')}")
            st.markdown(f"**ê´€ë ¨ì„± í‰ê°€**: {patent.get('grading_reason', 'N/A')}")
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì´ˆë¡ (Abstract)**")
                st.caption(patent.get("abstract", "N/A")[:500] + "..." if len(patent.get("abstract", "")) > 500 else patent.get("abstract", "N/A"))
            with col2:
                st.markdown("**ì²­êµ¬í•­ (Claims)**")
                st.caption(patent.get("claims", "N/A")[:500] + "..." if len(patent.get("claims", "")) > 500 else patent.get("claims", "N/A"))


# =============================================================================
# Footer
# =============================================================================

st.divider()
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem;">
    <p>âš¡ ì‡¼íŠ¹í—ˆ (Short-Cut) v3.0 | Self-RAG + Hybrid Search + Streaming</p>
    <p style="font-size: 0.8rem;">FAISS + BM25 + RRF | OpenAI API | Made with â¤ï¸ by Team ë€¨ğŸ’•</p>
</div>
""", unsafe_allow_html=True)
